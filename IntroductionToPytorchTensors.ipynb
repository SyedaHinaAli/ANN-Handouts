{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1) (100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a synthetic regression dataset using sklearn\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=15.0)\n",
    "print(X.shape, y.shape)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32).reshape(-1, 1)  # Reshaping y to make it 2D\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to PyTorch tensors\n",
    "X_tensor = torch.tensor(X)\n",
    "y_tensor = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataLoader using TensorDataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple linear regression model\n",
    "model = nn.Linear(1, 1)  # One input feature, one output for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m y_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Normalize the data using StandardScaler\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m scaler_X \u001b[38;5;241m=\u001b[39m \u001b[43mStandardScaler\u001b[49m()\n\u001b[0;32m     20\u001b[0m scaler_y \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m     22\u001b[0m X \u001b[38;5;241m=\u001b[39m scaler_X\u001b[38;5;241m.\u001b[39mfit_transform(X)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a simple regression dataset\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=15.0)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X)\n",
    "y_tensor = torch.tensor(y)\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X = scaler_X.fit_transform(X)\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# Create a dataset and dataloader\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Define a neural network model without using classes\n",
    "# It will have two hidden layers and one output layer\n",
    "input_size = 1\n",
    "hidden_size = 32\n",
    "output_size = 1\n",
    "\n",
    "# Define the layers\n",
    "layer1 = nn.Linear(input_size, hidden_size)  # Input -> Hidden Layer 1\n",
    "layer2 = nn.Linear(hidden_size, hidden_size) # Hidden Layer 1 -> Hidden Layer 2\n",
    "layer3 = nn.Linear(hidden_size, output_size) # Hidden Layer 2 -> Output\n",
    "\n",
    "# Define forward function manually\n",
    "def model(x):\n",
    "    x = torch.relu(layer1(x))  # Apply ReLU to the first hidden layer\n",
    "    x = torch.relu(layer2(x))  # Apply ReLU to the second hidden layer\n",
    "    x = layer3(x)              # Output layer\n",
    "    return x\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean squared error for regression\n",
    "optimizer = optim.Adam([*layer1.parameters(), *layer2.parameters(), *layer3.parameters()], lr=0.001)\n",
    "\n",
    "# Set the number of epochs for training\n",
    "num_epochs = 100\n",
    "\n",
    "# Training loop\n",
    "loss_values = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for data in dataloader:\n",
    "        feature, target = data\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        prediction = model(feature)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(prediction, target)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Average the loss over batches in the current epoch\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    loss_values.append(avg_loss)\n",
    "    \n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Plot the loss over epochs\n",
    "plt.plot(range(1, num_epochs + 1), loss_values, label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Function to show results\n",
    "def show_results():\n",
    "    with torch.no_grad():  # Disable gradient tracking for evaluation\n",
    "        features = []\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        \n",
    "        for data in dataloader:\n",
    "            feature, target = data\n",
    "            prediction = model(feature)\n",
    "            features.append(feature.numpy())\n",
    "            targets.append(target.numpy())\n",
    "            predictions.append(prediction.numpy())\n",
    "\n",
    "        features = np.concatenate(features)\n",
    "        targets = np.concatenate(targets)\n",
    "        predictions = np.concatenate(predictions)\n",
    "        \n",
    "        # Plot true vs predicted values\n",
    "        plt.scatter(features, targets, color='blue', label='True Values')\n",
    "        plt.scatter(features, predictions, color='red', label='Predicted Values')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Feature')\n",
    "        plt.ylabel('Target/Prediction')\n",
    "        plt.title('True vs Predicted Values')\n",
    "        plt.show()\n",
    "\n",
    "# Show the results\n",
    "show_results()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
